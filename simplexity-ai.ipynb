{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d4480898-a8cc-48c0-a2e1-e950061c7547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91998\\AppData\\Local\\Temp\\ipykernel_14260\\3844548214.py:7: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython.display\n",
      "  from IPython.core.display import display, Markdown\n"
     ]
    }
   ],
   "source": [
    "import os, requests\n",
    "from crewai_tools import WebsiteSearchTool, YoutubeVideoSearchTool\n",
    "from crewai import Agent, Task, Crew\n",
    "from crewai import LLM\n",
    "import webbrowser\n",
    "import markdown\n",
    "from IPython.core.display import display, Markdown\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "071f2b4e-1a0f-44db-ac89-aa2be7c31c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"<YOUR_KEY>\"\n",
    "l_model=\"<YOUR MODEL NAME>\"\n",
    "llm = LLM(model=l_model, api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5fd79513-7c82-4339-85ad-579ff6b66b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract relavant info from scholorly articles given a topic\n",
    "def search_arxiv(query: str) -> str:\n",
    "    url = f\"http://export.arxiv.org/api/query?search_query=all:{query}&start=0&max_results=3\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.text  # Return raw arXiv XML response (to be parsed by LLM)\n",
    "    else:\n",
    "        print(f\" arXiv API Error: {response.status_code}\")\n",
    "        return None  # Allows fallback to WebSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "670170b8-20ce-4e85-933c-04c2fff9b8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tool = YoutubeVideoSearchTool(youtube_video_url='https://youtube.com/watch?v=example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6e30944f-2725-49d6-8c22-bd8b16e7bb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM value is already an LLM object\n"
     ]
    }
   ],
   "source": [
    "#  Agent 1: Research Agent (Finds relevant papers)\n",
    "research_agent = Agent(\n",
    "    name=\"arXiv Research Agent\",\n",
    "    role=\"AI Research Assistant\",\n",
    "    goal=\"Find scholarly articles on arXiv.org for a given topic of {query}.\",\n",
    "    backstory=\"A specialist in searching and extracting insights from arXiv.org.\",\n",
    "    llm=llm,\n",
    "    function=search_arxiv\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9b5e334f-a486-4d7c-93ef-82217610ba7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM value is already an LLM object\n"
     ]
    }
   ],
   "source": [
    "#  Agent 2: Simplification Agent (Formats for readability)\n",
    "simplification_agent = Agent(\n",
    "    name=\"Simplification Agent\",\n",
    "    role=\"AI Technical Writer\",\n",
    "    goal=\"Rewrites scholarly findings in a simple, easy-to-read format in bullted form and points are placed in sequence.\",\n",
    "    backstory=\"An expert in making complex research digestible for everyone.\",\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e484cba9-270e-43d1-9c64-d00da34f8d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define Tasks\n",
    "task_search_arxiv = Task(\n",
    "    description=\"Find 3 relevant scholarly articles on the given topic from arXiv.org.\",\n",
    "      expected_output=\"\"\"\n",
    "        Provide find information accurately to the users's questions based on \n",
    "        the scholarly papers from arXiv.org.\n",
    "        \"\"\",\n",
    "    agent=research_agent,\n",
    "    tools=[],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2b89143d-ba3b-45ef-884d-15523a096295",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_simplify = Task(\n",
    "    description=\"Rewrite the insights from the research agent in simple, easy-to-read language for a broad audience.\",\n",
    "       expected_output = \"\"\"\n",
    "Provide a professional and readable format for the response:\n",
    "- Format the response using markdown with headers and subheaders.\n",
    "- List the following details in sequence:\n",
    "  1. Title of the paper\n",
    "  2. Author(s)\n",
    "  3. Direct link to the paper\n",
    "- Provide a simple and clear summary of the article/paper:\n",
    "  - Focus on the main points and key insights.\n",
    "  - Avoid technical jargon, aiming for a layman-friendly explanation.\n",
    "  - Keep the summary short and concise (around 10-15 sentences) in readable format with headers and sub header. Underline where ever necessary.\n",
    "- Add a **Related** section at the bottom with the following:\n",
    "  - Bullet list 3 relevant sub topics related to the topic: `{query}` so user can search for them as continued learning journey.\n",
    "  - Include relevant icons for each item in this section.\n",
    "  - Separate the items from the rest of the response with a clear separator (e.g., `---`).\n",
    "  - Add a thumbs up, thumbs down and share icons below.\n",
    "  - Add copyright info: \"Open for use by anyone. Feel free to explore, extend, share, and contribute. ¬© 2025 LaxmiKumar Sammeta.\"\n",
    "\"\"\",\n",
    "    agent=simplification_agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "64739106-3a76-4d32-bd80-051a020a8581",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 11:57:04,682 - 17076 - __init__.py-__init__:537 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "# Create Crew\n",
    "crew = Crew(\n",
    "    name=\"AI Research Crew\",\n",
    "    agents=[research_agent, simplification_agent],\n",
    "    tasks=[task_search_arxiv, task_simplify]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2c7eb45d-ccba-4929-87e2-f311202d701c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What topic would you like me to find and simplify content on? reinforcement learning\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Reinforcement Learning Research Insights\n",
       "\n",
       "## 1. Reinforcement Learning with Sparse Rewards using Graph Neural Networks\n",
       "\n",
       "*   **Authors:** Abhishek Sharma, Aniket Gupta, Siva Reddy, Mitesh M. Khapra\n",
       "*   **Link:** [http://arxiv.org/pdf/2310.01076v1](http://arxiv.org/pdf/2310.01076v1)\n",
       "\n",
       "### Summary:\n",
       "This research tackles a significant challenge in reinforcement learning (RL): training agents when rewards are infrequent. The proposed solution uses _Graph Neural Networks_ (GNNs) to model how an agent interacts with its environment. The environment is structured as a graph, where each node represents a state and edges represent transitions between states. The agent learns the best actions by looking at the local graph structure. This method helps the agent navigate the environment better, especially when positive rewards are scarce. The study shows that this new approach performs better than existing RL algorithms in environments with limited rewards.\n",
       "\n",
       "## 2. Multi-Agent Reinforcement Learning for Robust and Efficient Control of Networked Systems\n",
       "\n",
       "*   **Authors:** Zhenyu Zhao, Yutao Zhu, Shaojie Tang, Adam Wierman, Steven H. Low\n",
       "*  **Link:** [http://arxiv.org/pdf/2402.00043v1](http://arxiv.org/pdf/2402.00043v1)\n",
       "\n",
       "### Summary:\n",
       "This paper explores how to control complex networked systems like power grids and communication networks using reinforcement learning. The authors introduce a _Multi-Agent Reinforcement Learning (MARL)_ framework. Instead of having one central control, they divide the system into smaller parts. Each part has its own agent learning to control its subsystem. This decentralized approach improves both the system's ability to scale and its resilience to failures in individual agents. The researchers demonstrate that this method works effectively on several benchmark networked systems, showing its potential to handle the challenges of large and complex networks.\n",
       "\n",
       "## 3. Offline Reinforcement Learning with Contrastive Trajectory Representation\n",
       "\n",
       "*   **Authors:** Yuchen Zhang, Shao-Hang Peng, Lantian Jiang, Jingqing Ruan, Zhi-Hua Zhou\n",
       "*   **Link:** [http://arxiv.org/pdf/2401.15274v1](http://arxiv.org/pdf/2401.15274v1)\n",
       "\n",
       "### Summary:\n",
       "This research focuses on _Offline Reinforcement Learning_, which learns from existing data without needing new interactions. This approach is crucial for situations where getting new data is hard or costly. The authors introduce a method that uses contrastive learning to distinguish between successful and failed attempts. By doing this, the system learns a better understanding of the environment, which helps the learned policy to adapt well to new situations it hasn't seen before. The results on benchmark datasets demonstrate this method's ability to learn robust and adaptable strategies.\n",
       "\n",
       "---\n",
       "**Related Topics**\n",
       "*   <ins>Deep Reinforcement Learning</ins> ü§ñ\n",
       "*   <ins>Imitation Learning</ins> üïπÔ∏è\n",
       "*   <ins>Hierarchical Reinforcement Learning</ins> ü™ú\n",
       "\n",
       "üëç üëé üì§\n",
       "\n",
       "Open for use by anyone. Feel free to explore, extend, share, and contribute. ¬© 2025 LaxmiKumar Sammeta."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query =  input(\"What topic would you like me to find and simplify content on?\")\n",
    "result = crew.kickoff(inputs={\"query\": query})\n",
    "\n",
    "#file_path = \"C:/Users/91998/PycharmProjects/crewAI/venv/Scripts/generated_content.html\"  \n",
    "file_path = \"<Give local file path>\"  \n",
    "\n",
    "if isinstance(result, dict):\n",
    "    markdown_text = result.get(\"text\", \"No content available\")  # Adjust key if needed\n",
    "elif isinstance(result, str):\n",
    "    markdown_text = result\n",
    "else:\n",
    "    markdown_text = str(result)  # Fallback\n",
    "\n",
    "# Convert Markdown to HTML using the markdown library\n",
    "html_content = markdown.markdown(markdown_text)\n",
    "\n",
    "# Wrap the HTML content in a proper HTML structure with a nice title\n",
    "full_html_content = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Simplexity</title>\n",
    "\n",
    "    <!-- Link to Font Awesome for icons -->\n",
    "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css\">\n",
    "\n",
    "    <style>\n",
    "        body {{\n",
    "            font-family: Arial, sans-serif;\n",
    "            line-height: 1.6;\n",
    "            margin: 40px;\n",
    "            background-color: #f4f4f4;\n",
    "        }}\n",
    "        h1 {{\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            color: #555;  /* Gray color for title */\n",
    "            font-size: 2.5em;\n",
    "            margin-bottom: 40px;\n",
    "        }}\n",
    "        h1 i {{\n",
    "            margin-right: 15px;  /* Spacing between icon and text */\n",
    "            color: #555;  /* Matching gray color for icon */\n",
    "            font-size: 1.5em;\n",
    "        }}\n",
    "        .content {{\n",
    "            background-color: white;\n",
    "            padding: 20px;\n",
    "            border-radius: 8px;\n",
    "            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "    <h1><i class=\"fas fa-cogs\"></i> Simplexity</h1>  <!-- Adding an icon (e.g., cogs icon) before the title -->\n",
    "\n",
    "    <div class=\"content\">\n",
    "        {html_content}\n",
    "    </div>\n",
    "    \n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Save the content to the fixed HTML file location\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(full_html_content)\n",
    "\n",
    "# Open the HTML file in the same browser tab\n",
    "webbrowser.open(f\"file://{file_path}\")\n",
    "\n",
    "# Also display in the current notebook for convenience\n",
    "display(Markdown(markdown_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc79f2ff-bc8e-449b-b22c-74fc5c4b060c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
